{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931892d9",
   "metadata": {},
   "source": [
    "# XGBoost Nowcasting — Notebook (cells tách riêng)\n",
    "Dự báo mưa 60 phút tới từ dữ liệu IoT 5 phút. Không lưu model, chỉ in metrics.\n",
    "\n",
    "**Yêu cầu dữ liệu** đặt trong `data/`:\n",
    "- `sensor_raw_60d.csv`\n",
    "- `labels_rain_60d.csv`\n",
    "- `irrigation_events_60d.csv` (tùy chọn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02fd4c",
   "metadata": {},
   "source": [
    "## 0) Cài thư viện (chạy một lần nếu chưa có)\n",
    "```bash\n",
    "!pip install pandas numpy scikit-learn xgboost\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122ea8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbce941",
   "metadata": {},
   "source": [
    "## 1) Load dữ liệu & ghép nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35524222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: raw=(17280, 7), labels=(17280, 4), merged=(17280, 8)\n"
     ]
    }
   ],
   "source": [
    "RAW_CSV = \"../data/sensor_raw_60d.csv\"\n",
    "LBL_CSV = \"../data/labels_rain_60d_fixed.csv\"\n",
    "IRRIG_CSV = \"../data/irrigation_events_60d.csv\"  # optional\n",
    "\n",
    "raw = pd.read_csv(RAW_CSV, parse_dates=[\"ts\"]).sort_values([\"device_id\",\"ts\"]).reset_index(drop=True)\n",
    "lbl = pd.read_csv(LBL_CSV, parse_dates=[\"ts\"])  # contains rain_next_60\n",
    "\n",
    "df = raw.merge(lbl[[\"ts\",\"device_id\",\"rain_next_60\"]], on=[\"ts\",\"device_id\"], how=\"inner\")\n",
    "print(f\"Loaded: raw={raw.shape}, labels={lbl.shape}, merged={df.shape}\")\n",
    "\n",
    "def enrich_irrigation(df: pd.DataFrame, irrig_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Đánh dấu các mốc đang tưới và tổng phút tưới 3h/6h. Nếu không có file -> điền 0.\"\"\"\n",
    "    try:\n",
    "        irrig = pd.read_csv(irrig_path, parse_dates=[\"start_ts\",\"end_ts\"])\n",
    "    except Exception:\n",
    "        df[\"is_irrigating_now\"], df[\"irrig_total_min_last_3h\"], df[\"irrig_total_min_last_6h\"] = 0, 0.0, 0.0\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"is_irrigating_now\"] = 0\n",
    "    for _, ev in irrig.iterrows():\n",
    "        mask = (\n",
    "            (df[\"device_id\"]==ev[\"device_id\"]) &\n",
    "            (df[\"ts\"]>=ev[\"start_ts\"]) & (df[\"ts\"]<=ev[\"end_ts\"]) \n",
    "        )\n",
    "        df.loc[mask, \"is_irrigating_now\"] = 1\n",
    "\n",
    "    df = df.sort_values([\"device_id\",\"ts\"]).reset_index(drop=True)\n",
    "    df[\"irrig_min_5\"] = df[\"is_irrigating_now\"] * 5\n",
    "    df[\"irrig_total_min_last_3h\"] = (\n",
    "        df.groupby(\"device_id\")[\"irrig_min_5\"].rolling(36, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"irrig_total_min_last_6h\"] = (\n",
    "        df.groupby(\"device_id\")[\"irrig_min_5\"].rolling(72, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df = enrich_irrigation(df, IRRIG_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676c821",
   "metadata": {},
   "source": [
    "## 2) Tạo đặc trưng (feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5017045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 68 cols | X: (17256, 68)  y: (17256,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vu The Van\\AppData\\Local\\Temp\\ipykernel_10708\\3805558836.py:55: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"device_id\", group_keys=False).apply(add_feats_pro)\n"
     ]
    }
   ],
   "source": [
    "# === Feature Engineering (Pro) — 15/30/60/120', deltas dài, rolling, time cycles ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = df.sort_values([\"device_id\",\"ts\"]).reset_index(drop=True)\n",
    "\n",
    "def add_feats_pro(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = g.copy()\n",
    "\n",
    "    base_cols = [\"temp_c\",\"rh_pct\",\"pressure_hpa\",\"soil_moist_pct\"]\n",
    "    # nếu có dữ liệu thời tiết ngoài, thêm vào pipeline\n",
    "    ext_cols = [c for c in [\"api_rain_prob_60\",\"api_rain_mm_60\",\"cloud_pct\",\"wind_mps\"] if c in g.columns]\n",
    "    all_cols = base_cols + ext_cols\n",
    "\n",
    "    # ---- Lags (15', 30', 60', 120')\n",
    "    for col in all_cols:\n",
    "        for k in (3, 6, 12, 24):\n",
    "            g[f\"{col}_lag{k}\"] = g[col].shift(k)\n",
    "\n",
    "    # ---- Rolling mean/std cho 30', 60', 120'\n",
    "    for col in all_cols:\n",
    "        for w in (6, 12, 24):\n",
    "            g[f\"{col}_mean{w}\"] = g[col].rolling(w).mean()\n",
    "            g[f\"{col}_std{w}\"]  = g[col].rolling(w).std()\n",
    "\n",
    "    # ---- Deltas dài (30', 60')\n",
    "    for col in all_cols:\n",
    "        g[f\"{col}_d30\"] = g[col] - g[col].shift(6)\n",
    "        g[f\"{col}_d60\"] = g[col] - g[col].shift(12)\n",
    "\n",
    "    # ---- Tín hiệu mưa quá khứ\n",
    "    if \"rain_mm_5min\" in g.columns:\n",
    "        g[\"rain_in_last_15m\"] = g[\"rain_mm_5min\"].rolling(3).sum().gt(0).astype(int)\n",
    "        g[\"rain_last_30m\"]    = g[\"rain_mm_5min\"].rolling(6).sum()\n",
    "        g[\"rain_last_60m\"]    = g[\"rain_mm_5min\"].rolling(12).sum()\n",
    "\n",
    "    # ---- Time features (chu kỳ ngày/tuần)\n",
    "    g[\"hour_of_day\"] = g[\"ts\"].dt.hour\n",
    "    g[\"day_of_week\"] = g[\"ts\"].dt.dayofweek\n",
    "    g[\"month\"]       = g[\"ts\"].dt.month\n",
    "\n",
    "    g[\"hod_sin\"] = np.sin(2*np.pi*g[\"hour_of_day\"]/24.0)\n",
    "    g[\"hod_cos\"] = np.cos(2*np.pi*g[\"hour_of_day\"]/24.0)\n",
    "    g[\"dow_sin\"] = np.sin(2*np.pi*(g[\"day_of_week\"]+1)/7.0)\n",
    "    g[\"dow_cos\"] = np.cos(2*np.pi*(g[\"day_of_week\"]+1)/7.0)\n",
    "\n",
    "    # ---- Một vài tương tác nhẹ (hữu ích cho mưa đối lưu)\n",
    "    if {\"pressure_hpa_d30\",\"rh_pct_d30\"}.issubset(g.columns):\n",
    "        g[\"rh_over_pressure_d30\"] = g[\"rh_pct_d30\"] / (g[\"pressure_hpa_d30\"].abs() + 1e-6)\n",
    "    if {\"pressure_hpa_d60\",\"rh_pct_d60\"}.issubset(g.columns):\n",
    "        g[\"rh_over_pressure_d60\"] = g[\"rh_pct_d60\"] / (g[\"pressure_hpa_d60\"].abs() + 1e-6)\n",
    "\n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"device_id\", group_keys=False).apply(add_feats_pro)\n",
    "\n",
    "# Bỏ các hàng đầu chuỗi (do lag/rolling) + reset index\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# ---- Danh sách FEATURES động: gồm base, external nếu có, lags/rolling/deltas/time/irrigation\n",
    "base_feats = [\n",
    "    # gốc\n",
    "    \"temp_c\",\"rh_pct\",\"pressure_hpa\",\"soil_moist_pct\",\"rain_mm_5min\",\n",
    "    # mưa quá khứ\n",
    "    \"rain_in_last_15m\",\"rain_last_30m\",\"rain_last_60m\",\n",
    "    # time encoding\n",
    "    \"hour_of_day\",\"day_of_week\",\"month\",\"hod_sin\",\"hod_cos\",\"dow_sin\",\"dow_cos\",\n",
    "    # tưới (nếu đã enrich)\n",
    "    \"is_irrigating_now\",\"irrig_total_min_last_3h\",\"irrig_total_min_last_6h\",\n",
    "]\n",
    "\n",
    "# thêm external nếu có\n",
    "ext_feats = [c for c in [\"api_rain_prob_60\",\"api_rain_mm_60\",\"cloud_pct\",\"wind_mps\"] if c in df.columns]\n",
    "\n",
    "# sinh tên lags/rolling/deltas cho tất cả cột gốc + external\n",
    "def expand(names):\n",
    "    out = []\n",
    "    for col in names:\n",
    "        out += [f\"{col}_lag{k}\" for k in (3,6,12,24)]\n",
    "        out += [f\"{col}_mean{w}\" for w in (6,12,24)]\n",
    "        out += [f\"{col}_std{w}\"  for w in (6,12,24)]\n",
    "        out += [f\"{col}_d30\", f\"{col}_d60\"]\n",
    "    return out\n",
    "\n",
    "dyn_from_base = expand([\"temp_c\",\"rh_pct\",\"pressure_hpa\",\"soil_moist_pct\"])\n",
    "dyn_from_ext  = expand(ext_feats) if ext_feats else []\n",
    "\n",
    "# tương tác\n",
    "inter_feats = [c for c in [\"rh_over_pressure_d30\",\"rh_over_pressure_d60\"] if c in df.columns]\n",
    "\n",
    "FEATURES = []\n",
    "for c in base_feats + ext_feats + dyn_from_base + dyn_from_ext + inter_feats:\n",
    "    if c in df.columns:\n",
    "        FEATURES.append(c)\n",
    "\n",
    "# tạo ma trận\n",
    "X = df[FEATURES].astype(\"float32\").values\n",
    "y = df[\"rain_next_60\"].astype(int).values   # dùng nhãn đã FIX/REBUILD\n",
    "print(f\"Features: {len(FEATURES)} cols | X: {X.shape}  y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a3ebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External features in use? False\n",
      "Current-rain features? True\n",
      "Label-like columns accidentally in X? False\n"
     ]
    }
   ],
   "source": [
    "# 1) In danh sách FEATURES để xem có cột rò rỉ tương lai không\n",
    "print(\"External features in use?\",\n",
    "      any(c in FEATURES for c in [\"api_rain_prob_60\",\"api_rain_mm_60\"]))\n",
    "print(\"Current-rain features?\",\n",
    "      any(c in FEATURES for c in [\"rain_mm_5min\",\"rain_last_30m\",\"rain_last_60m\"]))\n",
    "print(\"Label-like columns accidentally in X?\",\n",
    "      any(c in FEATURES for c in [\"rain_next_60\",\"rain_amount_next_60_mm\",\"rain_next_60_rebuilt\",\"rain_amount_next_60_mm_rebuilt\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276dca80",
   "metadata": {},
   "source": [
    "## 3) Chia train/val + Train XGBoost (early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4823b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.9624 | PR-AUC: 0.9264\n",
      "@0.50  Acc: 0.9714  Prec: 0.9290  Rec: 0.9290  F1: 0.9290\n",
      "Recall≥0.60 candidate thr: 0.614 (prec=0.9304, rec=0.9232)\n",
      "Model sẵn sàng. NGƯỠNG MẶC ĐỊNH: 0.614\n"
     ]
    }
   ],
   "source": [
    "# === Train XGBoost (opt params) + Early Stopping + Threshold Search (F1/Recall) — SAFE ===\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_fscore_support,\n",
    "    accuracy_score, precision_recall_curve\n",
    ")\n",
    "\n",
    "# 1) Split giữ thứ tự thời gian\n",
    "pos, neg = (y == 1).sum(), (y == 0).sum()\n",
    "scale_pos_weight = float(neg) / max(1.0, float(pos))\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.15, shuffle=False)\n",
    "\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xte, label=yte)\n",
    "\n",
    "# 2) Tham số khởi điểm tốt cho nowcasting mưa (có thể tinh chỉnh thêm)\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\", \"auc\"],\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"lambda\": 2.0,\n",
    "    \"alpha\": 0.0,\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"tree_method\": \"hist\",  # GPU: \"gpu_hist\"\n",
    "}\n",
    "\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=1200,\n",
    "    evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "# 3) Dự đoán proba trên tập validation theo best_iter\n",
    "\n",
    "def _predict_proba_booster(booster, Xmat):\n",
    "    dm = xgb.DMatrix(Xmat)\n",
    "    best_ntree_limit = getattr(booster, \"best_ntree_limit\", None)\n",
    "    best_iteration = getattr(booster, \"best_iteration\", None)\n",
    "    if best_ntree_limit is not None:\n",
    "        p = booster.predict(dm, ntree_limit=best_ntree_limit)\n",
    "    elif best_iteration is not None:\n",
    "        p = booster.predict(dm, iteration_range=(0, best_iteration + 1))\n",
    "    else:\n",
    "        p = booster.predict(dm)\n",
    "    return np.asarray(p).reshape(-1)\n",
    "\n",
    "proba = _predict_proba_booster(bst, Xte)\n",
    "\n",
    "# 4) Metric @0.50 (tham khảo)\n",
    "pred_05 = (proba >= 0.5).astype(int)\n",
    "auc = roc_auc_score(yte, proba)\n",
    "pr_auc = average_precision_score(yte, proba)\n",
    "prec05, rec05, f105, _ = precision_recall_fscore_support(yte, pred_05, average=\"binary\")\n",
    "acc05 = accuracy_score(yte, pred_05)\n",
    "print(f\"AUC-ROC: {auc:.4f} | PR-AUC: {pr_auc:.4f}\")\n",
    "print(f\"@0.50  Acc: {acc05:.4f}  Prec: {prec05:.4f}  Rec: {rec05:.4f}  F1: {f105:.4f}\")\n",
    "\n",
    "# 5) Quét ngưỡng: (a) F1-best, (b) Recall-first an toàn\n",
    "prec, rec, thr = precision_recall_curve(yte, proba)\n",
    "\n",
    "# F1-best (giữ nguyên)\n",
    "f1s = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "ix_f1 = int(np.argmax(f1s))\n",
    "thr_f1 = float(thr[ix_f1]) if ix_f1 < len(thr) else 0.5\n",
    "\n",
    "# Recall-first (safe): align độ dài, kiểm tra rỗng\n",
    "valid = np.isfinite(prec[:-1]) & np.isfinite(rec[:-1])\n",
    "prec_cut = prec[:-1][valid]\n",
    "rec_cut  = rec[:-1][valid]\n",
    "thr_cut  = thr[valid]\n",
    "\n",
    "target_recall = 0.60  # CHỈNH theo mục tiêu\n",
    "mask = rec_cut >= target_recall\n",
    "if np.any(mask):\n",
    "    cand_idx  = np.where(mask)[0]\n",
    "    cand_thr  = thr_cut[cand_idx]\n",
    "    cand_prec = prec_cut[cand_idx]\n",
    "    j_local   = int(np.argmax(cand_prec))\n",
    "    thr_rec   = float(cand_thr[j_local])\n",
    "    print(f\"Recall≥{target_recall:.2f} candidate thr: {thr_rec:.3f} (prec={cand_prec[j_local]:.4f}, rec={rec_cut[cand_idx][j_local]:.4f})\")\n",
    "else:\n",
    "    thr_rec = None\n",
    "    print(f\"Không có ngưỡng đạt Recall ≥ {target_recall:.2f} trên tập validation.\")\n",
    "\n",
    "# 6) Wrapper: dùng ngưỡng mặc định ƯU TIÊN RECALL -> F1 -> 0.5\n",
    "class XGBBoosterWithThreshold:\n",
    "    def __init__(self, booster, threshold):\n",
    "        self._booster = booster\n",
    "        self.threshold = float(threshold)\n",
    "    def predict_proba(self, Xmat):\n",
    "        p1 = _predict_proba_booster(self._booster, Xmat)\n",
    "        return np.c_[1.0 - p1, p1]\n",
    "    def predict(self, Xmat, threshold=None):\n",
    "        th = self.threshold if threshold is None else float(threshold)\n",
    "        p1 = _predict_proba_booster(self._booster, Xmat)\n",
    "        return (p1 >= th).astype(int)\n",
    "    def get_booster(self):\n",
    "        return self._booster\n",
    "\n",
    "default_thr = (thr_rec if (thr_rec is not None) else (thr_f1 if thr_f1 is not None else 0.5))\n",
    "model = XGBBoosterWithThreshold(bst, default_thr)\n",
    "print(f\"Model sẵn sàng. NGƯỠNG MẶC ĐỊNH: {model.threshold:.3f}\")\n",
    "\n",
    "# import json, joblib, os\n",
    "# os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# # 1) Lưu classifier 60'\n",
    "# joblib.dump(model, \"models/xgb_nowcast.pkl\")   # model có .predict_proba() và thuộc tính .threshold\n",
    "\n",
    "# # 2) (tuỳ chọn) lưu regressor lượng mưa 60' nếu bạn đã train\n",
    "# # joblib.dump(reg_model, \"models/xgb_amount.pkl\")\n",
    "\n",
    "# # 3) Lưu metadata (FEATURES + threshold)\n",
    "# meta = {\n",
    "#     \"features\": FEATURES,\n",
    "#     \"threshold_default\": float(getattr(model, \"threshold\", 0.5)),\n",
    "#     \"note\": \"XGBoost nowcasting 60' | threshold ưu tiên Recall nếu đã cấu hình\"\n",
    "# }\n",
    "# with open(\"models/metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(meta, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff18ad",
   "metadata": {},
   "source": [
    "## 4) Đánh giá: AUC/PR-AUC/Precision/Recall/F1 + báo cáo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e05d71c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.9624 | PR-AUC: 0.9264\n",
      "\n",
      "=== Summary by threshold ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ea762\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ea762_level0_col0\" class=\"col_heading level0 col0\" >threshold</th>\n",
       "      <th id=\"T_ea762_level0_col1\" class=\"col_heading level0 col1\" >accuracy</th>\n",
       "      <th id=\"T_ea762_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_ea762_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_ea762_level0_col4\" class=\"col_heading level0 col4\" >f1</th>\n",
       "      <th id=\"T_ea762_level0_col5\" class=\"col_heading level0 col5\" >tp</th>\n",
       "      <th id=\"T_ea762_level0_col6\" class=\"col_heading level0 col6\" >fp</th>\n",
       "      <th id=\"T_ea762_level0_col7\" class=\"col_heading level0 col7\" >tn</th>\n",
       "      <th id=\"T_ea762_level0_col8\" class=\"col_heading level0 col8\" >fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ea762_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ea762_row0_col0\" class=\"data row0 col0\" >0.500</td>\n",
       "      <td id=\"T_ea762_row0_col1\" class=\"data row0 col1\" >0.9714</td>\n",
       "      <td id=\"T_ea762_row0_col2\" class=\"data row0 col2\" >0.9290</td>\n",
       "      <td id=\"T_ea762_row0_col3\" class=\"data row0 col3\" >0.9290</td>\n",
       "      <td id=\"T_ea762_row0_col4\" class=\"data row0 col4\" >0.9290</td>\n",
       "      <td id=\"T_ea762_row0_col5\" class=\"data row0 col5\" >484</td>\n",
       "      <td id=\"T_ea762_row0_col6\" class=\"data row0 col6\" >37</td>\n",
       "      <td id=\"T_ea762_row0_col7\" class=\"data row0 col7\" >2031</td>\n",
       "      <td id=\"T_ea762_row0_col8\" class=\"data row0 col8\" >37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea762_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ea762_row1_col0\" class=\"data row1 col0\" >0.611</td>\n",
       "      <td id=\"T_ea762_row1_col1\" class=\"data row1 col1\" >0.9714</td>\n",
       "      <td id=\"T_ea762_row1_col2\" class=\"data row1 col2\" >0.9290</td>\n",
       "      <td id=\"T_ea762_row1_col3\" class=\"data row1 col3\" >0.9290</td>\n",
       "      <td id=\"T_ea762_row1_col4\" class=\"data row1 col4\" >0.9290</td>\n",
       "      <td id=\"T_ea762_row1_col5\" class=\"data row1 col5\" >484</td>\n",
       "      <td id=\"T_ea762_row1_col6\" class=\"data row1 col6\" >37</td>\n",
       "      <td id=\"T_ea762_row1_col7\" class=\"data row1 col7\" >2031</td>\n",
       "      <td id=\"T_ea762_row1_col8\" class=\"data row1 col8\" >37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea762_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ea762_row2_col0\" class=\"data row2 col0\" >0.614</td>\n",
       "      <td id=\"T_ea762_row2_col1\" class=\"data row2 col1\" >0.9706</td>\n",
       "      <td id=\"T_ea762_row2_col2\" class=\"data row2 col2\" >0.9304</td>\n",
       "      <td id=\"T_ea762_row2_col3\" class=\"data row2 col3\" >0.9232</td>\n",
       "      <td id=\"T_ea762_row2_col4\" class=\"data row2 col4\" >0.9268</td>\n",
       "      <td id=\"T_ea762_row2_col5\" class=\"data row2 col5\" >481</td>\n",
       "      <td id=\"T_ea762_row2_col6\" class=\"data row2 col6\" >36</td>\n",
       "      <td id=\"T_ea762_row2_col7\" class=\"data row2 col7\" >2032</td>\n",
       "      <td id=\"T_ea762_row2_col8\" class=\"data row2 col8\" >40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x208a6292270>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed report @threshold=0.614 ===\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9807    0.9826    0.9816      2068\n",
      "           1     0.9304    0.9232    0.9268       521\n",
      "\n",
      "    accuracy                         0.9706      2589\n",
      "   macro avg     0.9555    0.9529    0.9542      2589\n",
      "weighted avg     0.9706    0.9706    0.9706      2589\n",
      "\n",
      "--- Confusion Matrix (y_true rows x y_pred cols) ---\n",
      "[[2032   36]\n",
      " [  40  481]]\n"
     ]
    }
   ],
   "source": [
    "# === Evaluation (robust) ===\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_fscore_support,\n",
    "    precision_recall_curve, classification_report, confusion_matrix, accuracy_score\n",
    ")\n",
    "\n",
    "# ---- 1) Lấy proba từ model wrapper hoặc booster gốc\n",
    "proba = None\n",
    "\n",
    "if 'model' in globals() and hasattr(model, 'predict_proba'):\n",
    "    proba = model.predict_proba(Xte)[:, 1]\n",
    "\n",
    "if proba is None:\n",
    "    import xgboost as xgb\n",
    "    if 'bst' in globals():\n",
    "        dte = xgb.DMatrix(Xte)\n",
    "        best_ntree_limit = getattr(bst, 'best_ntree_limit', None)\n",
    "        best_iteration   = getattr(bst, 'best_iteration', None)\n",
    "        if best_ntree_limit is not None:\n",
    "            proba = bst.predict(dte, ntree_limit=best_ntree_limit)\n",
    "        elif best_iteration is not None:\n",
    "            proba = bst.predict(dte, iteration_range=(0, best_iteration + 1))\n",
    "        else:\n",
    "            proba = bst.predict(dte)\n",
    "    else:\n",
    "        raise RuntimeError(\"Chưa có `model` hay `bst`. Hãy chạy cell Train trước.\")\n",
    "\n",
    "proba = np.asarray(proba).reshape(-1)\n",
    "\n",
    "# ---- 2) AUC & PR-AUC\n",
    "auc = roc_auc_score(yte, proba)\n",
    "pr_auc = average_precision_score(yte, proba)\n",
    "print(f\"AUC-ROC: {auc:.4f} | PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# ---- 3) các ngưỡng cần đánh giá\n",
    "def metrics_at(y_true, p, thr):\n",
    "    pred = (p >= thr).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, pred, average=\"binary\", zero_division=0)\n",
    "    acc = accuracy_score(y_true, pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()\n",
    "    return {\n",
    "        \"threshold\": float(thr),\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision\": float(prec),\n",
    "        \"recall\": float(rec),\n",
    "        \"f1\": float(f1),\n",
    "        \"tp\": int(tp), \"fp\": int(fp), \"tn\": int(tn), \"fn\": int(fn)\n",
    "    }\n",
    "\n",
    "# 3a) @0.50\n",
    "rows = [metrics_at(yte, proba, 0.5)]\n",
    "\n",
    "# 3b) @model.threshold (nếu có)\n",
    "chosen_thr = None\n",
    "if 'model' in globals() and hasattr(model, 'threshold'):\n",
    "    rows.append(metrics_at(yte, proba, float(model.threshold)))\n",
    "    chosen_thr = float(model.threshold)\n",
    "\n",
    "# 3c) @best-F1 (quét theo PR curve)\n",
    "prec, rec, thr = precision_recall_curve(yte, proba)\n",
    "f1s = 2*prec*rec/(prec+rec+1e-12)\n",
    "ix = f1s.argmax()\n",
    "thr_f1 = float(thr[ix]) if ix < len(thr) else 0.5\n",
    "rows.append(metrics_at(yte, proba, thr_f1))\n",
    "\n",
    "# ---- 4) In bảng tóm tắt\n",
    "import pandas as pd\n",
    "eval_df = pd.DataFrame(rows).drop_duplicates(subset=[\"threshold\"]).sort_values(\"threshold\").reset_index(drop=True)\n",
    "print(\"\\n=== Summary by threshold ===\")\n",
    "display(eval_df.style.format({\"threshold\": \"{:.3f}\", \"accuracy\": \"{:.4f}\", \"precision\": \"{:.4f}\", \"recall\":\"{:.4f}\", \"f1\":\"{:.4f}\"}))\n",
    "\n",
    "# ---- 5) Chọn ngưỡng để báo cáo chi tiết\n",
    "# Ưu tiên: model.threshold nếu có, nếu không dùng best-F1\n",
    "if chosen_thr is None:\n",
    "    chosen_thr = thr_f1\n",
    "\n",
    "pred = (proba >= chosen_thr).astype(int)\n",
    "print(f\"\\n=== Detailed report @threshold={chosen_thr:.3f} ===\\n\")\n",
    "print(classification_report(yte, pred, digits=4))\n",
    "print(\"--- Confusion Matrix (y_true rows x y_pred cols) ---\")\n",
    "print(confusion_matrix(yte, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083b0d4d",
   "metadata": {},
   "source": [
    "## 5) Feature importance (gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db7a9423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temp_c</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rh_pct</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pressure_hpa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soil_moist_pct</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rain_mm_5min</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pressure_delta15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rh_delta15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>temp_delta15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>temp_c_lag15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rh_pct_lag15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pressure_hpa_lag15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>soil_moist_pct_lag15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>temp_c_mean30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rh_pct_mean30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pressure_hpa_mean30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soil_moist_pct_mean30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rain_in_last_15m</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hour_of_day</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is_irrigating_now</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  gain\n",
       "0                  temp_c   0.0\n",
       "1                  rh_pct   0.0\n",
       "2            pressure_hpa   0.0\n",
       "3          soil_moist_pct   0.0\n",
       "4            rain_mm_5min   0.0\n",
       "5        pressure_delta15   0.0\n",
       "6              rh_delta15   0.0\n",
       "7            temp_delta15   0.0\n",
       "8            temp_c_lag15   0.0\n",
       "9            rh_pct_lag15   0.0\n",
       "10     pressure_hpa_lag15   0.0\n",
       "11   soil_moist_pct_lag15   0.0\n",
       "12          temp_c_mean30   0.0\n",
       "13          rh_pct_mean30   0.0\n",
       "14    pressure_hpa_mean30   0.0\n",
       "15  soil_moist_pct_mean30   0.0\n",
       "16       rain_in_last_15m   0.0\n",
       "17            hour_of_day   0.0\n",
       "18            day_of_week   0.0\n",
       "19      is_irrigating_now   0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = model.get_booster().get_score(importance_type='gain')\n",
    "imp_list = [(f, importances.get(f, 0.0)) for f in FEATURES]\n",
    "imp_df = pd.DataFrame(imp_list, columns=[\"feature\",\"gain\"]).sort_values(\"gain\", ascending=False)\n",
    "imp_df.reset_index(drop=True, inplace=True)\n",
    "imp_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0c3f2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence y=1: 0.2324 (4014/17275)\n",
      "Val prevalence: 0.201 (521/2592)\n",
      "Baseline F1(all-0): 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "print(\"Prevalence y=1:\", y.mean().round(4), f\"({y.sum()}/{len(y)})\")\n",
    "print(\"Val prevalence:\", yte.mean().round(4), f\"({yte.sum()}/{len(yte)})\")\n",
    "# Baseline đoán toàn 0\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Baseline F1(all-0):\", f1_score(yte, np.zeros_like(yte)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0f12b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  rain_next_60  rain_in_last_15m\n",
      "rain_next_60             1.000             0.511\n",
      "rain_in_last_15m         0.511             1.000\n",
      "Corr with shifted y: 0.513\n"
     ]
    }
   ],
   "source": [
    "tmp = pd.DataFrame({\n",
    "    \"rain_next_60\": y,\n",
    "    \"rain_in_last_15m\": df.loc[:, \"rain_in_last_15m\"].values\n",
    "})\n",
    "print(tmp.corr().round(3))\n",
    "# Nếu hệ số ~0 hoặc âm -> nghi lệch thời gian/merge sai.\n",
    "# Thử dịch nhãn +1 step xem có tăng tương quan không:\n",
    "y_shifted = np.roll(y, -3)  # lệch 15'\n",
    "print(\"Corr with shifted y:\", np.corrcoef(y_shifted[:-3], tmp[\"rain_in_last_15m\"].values[:-3])[0,1].round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f827933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates (device_id, ts): 0\n"
     ]
    }
   ],
   "source": [
    "dup = df.duplicated(subset=[\"device_id\",\"ts\"]).sum()\n",
    "print(\"Duplicates (device_id, ts):\", dup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b032d91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Using cached flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (3.0.5)\n",
      "Collecting blinker>=1.9.0 (from flask)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from flask) (3.0.3)\n",
      "Collecting werkzeug>=3.1.0 (from flask)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from xgboost) (1.16.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vu the van\\anaconda3\\envs\\weather\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, python-dotenv, itsdangerous, click, blinker, flask\n",
      "\n",
      "   ---------------------------------------- 0/6 [werkzeug]\n",
      "   -------------------------- ------------- 4/6 [blinker]\n",
      "   ---------------------------------------- 6/6 [flask]\n",
      "\n",
      "Successfully installed blinker-1.9.0 click-8.3.0 flask-3.1.2 itsdangerous-2.2.0 python-dotenv-1.1.1 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install flask python-dotenv pandas numpy joblib xgboost\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
